{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86305c9-8df0-4ea6-9f1b-415f61e390ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861e3afb-586f-47b6-87f2-a3de3398c5db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6018cf8e-bc4a-4865-bcbd-7235c82f4a42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 16:36:09.893419: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 16:36:14.362508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-05-19 16:36:14.364056: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-05-19 16:36:14.364083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from RecommenderModel import RecommenderModel\n",
    "from ModelConfig import ModelConfig\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,SparseCategoricalCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from FileReader import FileReader\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1020f823-bf21-42be-8702-bf6904a9459e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr=FileReader('aiml_harveen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bdd247f-04cb-448a-a7e1-bc94bb41a8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_train=fr.readText('movie/recommender/orig_data/content_item_train.csv')\n",
    "user_train=fr.readText('movie/recommender/orig_data/content_user_train.csv')\n",
    "y_train=fr.readText('movie/recommender/orig_data/content_y_train.csv')\n",
    "item_vecs = fr.readText('movie/recommender/orig_data/content_item_vecs.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0a5a7e-8a50-4ece-9e1f-4b0f1dfb8d17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training vectors: 50884\n"
     ]
    }
   ],
   "source": [
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "\n",
    "\n",
    "print(f\"Number of training vectors: {len(item_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb2c6fe-4453-46dc-be5a-7b95e7e9b75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_train_unscaled = item_train\n",
    "user_train_unscaled = item_train\n",
    "y_train_unscaled    = item_train\n",
    "\n",
    "scalerItem = StandardScaler()\n",
    "scalerItem.fit(item_train)\n",
    "item_train = scalerItem.transform(item_train)\n",
    "\n",
    "scalerUser = StandardScaler()\n",
    "scalerUser.fit(user_train)\n",
    "user_train = scalerUser.transform(user_train)\n",
    "\n",
    "scalerTarget = MinMaxScaler((-1, 1))\n",
    "scalerTarget.fit(y_train.reshape(-1, 1))\n",
    "y_train = scalerTarget.transform(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7e5e5e-eeaa-4e89-8eac-9d117ee6597f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie/item training data shape: (40707, 17)\n",
      "movie/item test data shape: (10177, 17)\n"
     ]
    }
   ],
   "source": [
    "item_train, item_test = train_test_split(item_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "user_train, user_test = train_test_split(user_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)\n",
    "print(f\"movie/item training data shape: {item_train.shape}\")\n",
    "print(f\"movie/item test data shape: {item_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b624e50-1ee1-405d-ad92-b2ebc513d389",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 16:36:21.668128: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-05-19 16:36:21.669478: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-05-19 16:36:21.669577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-20240502-111332): /proc/driver/nvidia/version does not exist\n",
      "2024-05-19 16:36:21.682770: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "modelConfig=ModelConfig(\n",
    "    model_type=\"recommender\",\n",
    "    layers=[[\"relu\",\"relu\",\"linear\"],[\"relu\",\"relu\",\"linear\"]],\n",
    "    regularizers=[[0.00,0.00,0.00],[0.00,0.00,0.00]],\n",
    "    neurons=[[256,128,32],[256,128,32]],\n",
    "    epochs=30,\n",
    "    loss=MeanSquaredError(),\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    verbose=1,\n",
    "    no_of_networks=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67c4aefe-a745-4be3-95fc-362fd2f87ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recoModel = RecommenderModel(modelConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a639710-60a6-4a87-a3b7-9db56adf6fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 32)           41632       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 32)           41632       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize (TFOpLamb  (None, 32)          0           ['sequential[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_1 (TFOpLa  (None, 32)          0           ['sequential_1[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['tf.math.l2_normalize[0][0]',   \n",
      "                                                                  'tf.math.l2_normalize_1[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 83,264\n",
      "Trainable params: 83,264\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "1273/1273 [==============================] - 5s 3ms/step - loss: 0.1229\n",
      "Epoch 2/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.1146\n",
      "Epoch 3/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.1105\n",
      "Epoch 4/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.1058\n",
      "Epoch 5/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.1031\n",
      "Epoch 6/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0998\n",
      "Epoch 7/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0971\n",
      "Epoch 8/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0950\n",
      "Epoch 9/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0926\n",
      "Epoch 10/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0911\n",
      "Epoch 11/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0891\n",
      "Epoch 12/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0873\n",
      "Epoch 13/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0860\n",
      "Epoch 14/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0847\n",
      "Epoch 15/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0834\n",
      "Epoch 16/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0822\n",
      "Epoch 17/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0810\n",
      "Epoch 18/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0799\n",
      "Epoch 19/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0790\n",
      "Epoch 20/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0780\n",
      "Epoch 21/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0770\n",
      "Epoch 22/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0764\n",
      "Epoch 23/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0753\n",
      "Epoch 24/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0746\n",
      "Epoch 25/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0736\n",
      "Epoch 26/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0730\n",
      "Epoch 27/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0723\n",
      "Epoch 28/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0715\n",
      "Epoch 29/30\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0709\n",
      "Epoch 30/30\n",
      "1273/1273 [==============================] - 4s 3ms/step - loss: 0.0704\n"
     ]
    }
   ],
   "source": [
    "recoModel.train([item_train,user_train],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a66642-40be-4ca4-b717-9057adcdb5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 1s 2ms/step - loss: 0.0808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08080785721540451"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recoModel.model.evaluate([item_test,user_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8fd9ec5-0e7d-414a-b3e2-eb7059ecb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 0.0\n",
    "new_action = 0.0\n",
    "new_adventure = 5.0\n",
    "new_animation = 0.0\n",
    "new_childrens = 0.0\n",
    "new_comedy = 0.0\n",
    "new_crime = 0.0\n",
    "new_documentary = 0.0\n",
    "new_drama = 0.0\n",
    "new_fantasy = 5.0\n",
    "new_horror = 0.0\n",
    "new_mystery = 0.0\n",
    "new_romance = 0.0\n",
    "new_scifi = 0.0\n",
    "new_thriller = 0.0\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1e21a-3475-4bd4-9a29-356498bacde7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56fa8556-9a52-45b0-9ff5-fbcb4818bad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_vecs = np.tile(user_vec, (len(item_vecs), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "10789c73-0f2d-4591-9e08-c161122086bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "suser_vecs = scalerUser.transform(user_vec)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "435210a3-ff11-4604-b9f3-75b3398fdbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.3020864 , -1.2142439 , -7.48604051, -5.88972698,  2.55623364,\n",
       "        -3.76612966, -3.46393965, -5.68465283, -5.16081591, -1.244141  ,\n",
       "        -6.75133877,  2.08698324, -2.2559249 , -4.68122296, -4.86517161,\n",
       "        -5.00476899, -5.67635045]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suser_vecs[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db64e844-5963-4b91-a3e2-3eb06fc4a89b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "847"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbb734d5-1ae1-4103-8864-58dc135be90e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(847, 17)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sitem_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75a01b45-b766-43e5-b845-c2aec544755c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 847, 1\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_p \u001b[38;5;241m=\u001b[39m \u001b[43mrecoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msitem_vecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43msuser_vecs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/data_adapter.py:1848\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1842\u001b[0m         label,\n\u001b[1;32m   1843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1844\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1845\u001b[0m         ),\n\u001b[1;32m   1846\u001b[0m     )\n\u001b[1;32m   1847\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1848\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 847, 1\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "y_p = recoModel.model.predict([sitem_vecs,suser_vecs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87438f3-221b-4665-8381-c4218b3caf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2cfc9d1a-eb1c-49d6-9bd4-484d2e4adbd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pu = scalerTarget.inverse_transform(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fc5e53ff-92ce-44a9-ad04-5f4b85b4eaec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b8268-1520-4481-b72a-4cd1138e2c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_ypu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3960d49-fff9-4aea-a529-10d561993f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
